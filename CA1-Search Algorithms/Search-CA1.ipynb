{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA1: Search Algorithms\n",
    "## Amir Ali Vahidi 810199511\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import needed libraries for further uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import copy\n",
    "import time\n",
    "import heapq\n",
    "from colorama import Fore, Back, Style"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graph class for implementing the problem graph\n",
    "parameters in __ __init__ __ function:\n",
    "- `seyed_location`: current seyed location\n",
    "- `edges`: graph edges\n",
    "- `recipes`: two-dimensional list that contains every morid's needed recipes\n",
    "- `morids`: list of locations of morids\n",
    "- `difficult_vertices`: list of difficult vertices given in input\n",
    "- `pass_count_difficult_vertices`: stores numbers of passes of difficult vertices(updated every time seyed passes a difficult vertice)\n",
    "- `decreasing_count_dif_ver`: it is used for aknowledging of how long seyed should stay in a difficult vertice(initial value = pass_count_difficult_vertices and decreses when seyed is on a difficult vertice until it reaches 0 and then seyed is allowed to pass this difficult vertice)\n",
    "- `path`: state path\n",
    "- `total_cost`: cost of this state path\n",
    "- `recipe_or_morid_visited_node_counted`: number of visited nodes in this path that contains either morid or recipe or both\n",
    "- `not_empty_nodes`: number of all nodes in graph that contains either morid or recipe or both\\\n",
    "\n",
    "__ __iter__ __ functions is used to return a hash for a state based on three parameters:\n",
    "- seyed current location\n",
    "- morids visited and fully satisfied\n",
    "- recipes gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self,seyed_location,edges,recipes,morids,difficult_vertices,pass_count_diffucult_vertices, decreasing_count_dif_ver,not_empty_nodes):\n",
    "        self.seyed_location=seyed_location\n",
    "        self.edges=edges\n",
    "        self.recipes=recipes\n",
    "        self.morids=morids\n",
    "        self.difficult_vertices=difficult_vertices\n",
    "        self.pass_count_diffucult_vertices=pass_count_diffucult_vertices\n",
    "        self.decreasing_count_dif_ver= decreasing_count_dif_ver\n",
    "        self.path=str(seyed_location)+\" -> \"\n",
    "        self.total_cost=0\n",
    "        self.recipe_or_morid_visited_node_counted=0\n",
    "        self.not_empty_nodes=not_empty_nodes\n",
    "    # def __hash__(self) -> int:\n",
    "    #     print(tuple(self.seyed_location,tuple(self.pass_count_diffucult_vertices)))\n",
    "    #     print(tuple(self.pass_count_diffucult_vertices))\n",
    "    #     return hash((self.seyed_location,self.recipes,self.morids,self.pass_count_diffucult_vertices,self.decreasing_count_dif_ver))\n",
    "    def __iter__(self):\n",
    "        to_be_hashed =[]\n",
    "        to_be_hashed.append(self.seyed_location)\n",
    "        for morid in self.morids:           \n",
    "            to_be_hashed.append(morid)\n",
    "            for recipe in self.recipes[morid]:\n",
    "                to_be_hashed.append(recipe)\n",
    "        yield tuple(to_be_hashed)  \n",
    "\n",
    "    def get_recipe_or_morids_visited_count(self):\n",
    "        return self.recipe_or_morid_visited_node_counted\n",
    "    \n",
    "    def get_not_empty_nodes_count(self):\n",
    "        return sum(self.not_empty_nodes) \n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(input_file_address):\n",
    "    file = open(input_file_address)\n",
    "\n",
    "    n, m = map(int,file.readline().split(\" \"))\n",
    "    not_empty_nodes=[False for _ in range(n+1)]\n",
    "    edges = []   \n",
    "    for i in range(m):\n",
    "        u, v = map(int,file.readline().split(\" \"))\n",
    "        edges.append((u,v))\n",
    "        \n",
    "    h = int(file.readline())\n",
    "    pass_count_dif_ver=[0 for _ in range(h)]\n",
    "    decreasing_count_dif_ver=[0 for _ in range(h)]\n",
    "    difficult_vertices=list(map(int,file.readline().split()))\n",
    "\n",
    "    s= int(file.readline())\n",
    "    morids_location=[]\n",
    "    recipes=[[] for _ in range(n+1)]\n",
    "    for _ in range(s):\n",
    "        line = file.readline()\n",
    "        morid_location=int(line.split()[0])\n",
    "        morids_location.append(morid_location)\n",
    "        not_empty_nodes[morid_location]=True\n",
    "        morids_number_of_recipes=int(line.split()[1])\n",
    "        recipes[morid_location]=list(map(int,line.split()[2:morids_number_of_recipes+2]))\n",
    "        for recipe in recipes[morid_location]:\n",
    "            not_empty_nodes[recipe]=True\n",
    "\n",
    "    v = int(file.readline())\n",
    "\n",
    "    return Graph(seyed_location=v,edges=edges,recipes=recipes,morids=morids_location,difficult_vertices=difficult_vertices,pass_count_diffucult_vertices=pass_count_dif_ver, decreasing_count_dif_ver= decreasing_count_dif_ver,not_empty_nodes=not_empty_nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Update properties of the state and return a new state\n",
    "parameters to check:\n",
    "- `difficult vertices`: check if seyed current location is on difficult vertices and update decreasing_count_dif_ver and pass_count_diffucult_vertices if so\n",
    "- `recipes`: if seyed current location contains a recipe it will be removed from wanted recipes list\n",
    "- `morids`: if seyed current location contains a morid and morids wanted recipes are already gathered, this morid will be removed from wanted morids list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(present_state: Graph,this_frontier):\n",
    "    present_state = copy.deepcopy(present_state)\n",
    "    present_state.seyed_location = this_frontier\n",
    "    present_state.total_cost+=1\n",
    "    # check if this_frontier is a difficult_vertices and update if so\n",
    "    if this_frontier in present_state.difficult_vertices:\n",
    "        index=present_state.difficult_vertices.index(this_frontier)\n",
    "        # check if Seyed is thinking about purpose of Dizzy Mazgan\n",
    "        if present_state.decreasing_count_dif_ver[index]>0:\n",
    "            present_state.total_cost+=1\n",
    "            present_state.decreasing_count_dif_ver[index]-=1\n",
    "        # Seyed is not thinking about purpose of Dizzy Mazgan anymore\n",
    "        else:\n",
    "            present_state.pass_count_diffucult_vertices[index]+=1\n",
    "            present_state.decreasing_count_dif_ver[index]=present_state.pass_count_diffucult_vertices[index]\n",
    "    \n",
    "    \n",
    "    recipe_or_morid_visited=False\n",
    "\n",
    "    # check if this_frontier contains a recipe\n",
    "    for morid in present_state.morids: \n",
    "        if this_frontier in present_state.recipes[morid]:\n",
    "            recipe_or_morid_visited=True\n",
    "            present_state.recipes[morid].remove(this_frontier)\n",
    "   \n",
    "    # remove morids that have been visited\n",
    "    if this_frontier in present_state.morids:\n",
    "        # check if Morid can be visited(recipes of this Morid should be visited earlier)\n",
    "        if len(present_state.recipes[this_frontier])==0:\n",
    "            recipe_or_morid_visited=True\n",
    "            present_state.morids.remove(this_frontier)\n",
    "       \n",
    "    #morids_to_be_remove_index=[index for (index, morid) in enumerate(present_state.morids) if morid == this_frontier]\n",
    "\n",
    "    # count visited nodes containing morid or recipe\n",
    "    if recipe_or_morid_visited:\n",
    "        present_state.recipe_or_morid_visited_node_counted+=1\n",
    "\n",
    "        \n",
    "    return present_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DZ Ready?\n",
    "check if all `recipes` had beed gathered and all `morids` have recieved theirs and return \"True\" if so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_final_state(state: Graph):\n",
    "    number_of_morids=len(state.morids)\n",
    "    if number_of_morids>0:\n",
    "        return False\n",
    "    for i in range(number_of_morids):\n",
    "        if len(state.recipes[i])>0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_encoder(state):\n",
    "    return hash(tuple(state))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BFS (Uninformed)\n",
    "starting of the initail seyed location, we add this state in the frontier_state queue.\\\n",
    "on every state, we first check whether it already exists in visited_states and if so, we continue the loop without calculating rest of this state path because it has already been calculated.\n",
    "if this state has not already been visited, we add this state to the visited_states and check its adjacent nodes and if any of them satisfies the final state conditions, we save or update it's information and after finishing the serach of this depth of bfs, we return the rusult!\\\n",
    "after gaining this node's adjacent states, we add them to the frontier_state and continue the loop until a state satisfies the goal state conditions!\n",
    "\n",
    "##### Pros:\n",
    "- It return an optimal solution\n",
    "- In Comparison to DFS and some other search algorithms, it has a better time complexity\n",
    "\n",
    "##### Cons:\n",
    "- In comparison to A* and some other search algorithms, it has a worse time complexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFS(input_file_address):\n",
    "    frontier_states=deque()\n",
    "    visited_states=set()\n",
    "    frontier_states.append(open_file(input_file_address))\n",
    "    visited_state_count=1\n",
    "    path,total_cost=0,float('inf')\n",
    "    while(frontier_states):\n",
    "        present_state=frontier_states.popleft()\n",
    "        encoded_state=state_encoder(present_state)\n",
    "        if encoded_state in visited_states:\n",
    "            continue\n",
    "        else:\n",
    "            visited_states.add(encoded_state)\n",
    "            visited_state_count+=1\n",
    "        \n",
    "        \n",
    "        neighbors_dict=[item for item in present_state.edges if present_state.seyed_location in item]\n",
    "        for neighbor in neighbors_dict:\n",
    "            if neighbor[0]==present_state.seyed_location:\n",
    "                this_frontier=neighbor[1]\n",
    "            else:\n",
    "                this_frontier=neighbor[0]\n",
    "\n",
    "            new_state=expand(present_state=present_state,this_frontier=this_frontier)\n",
    "            new_state.path+=str(new_state.seyed_location)\n",
    "\n",
    "            if is_final_state(new_state):\n",
    "                if total_cost > new_state.total_cost:\n",
    "                    path,total_cost = new_state.path,new_state.total_cost\n",
    "\n",
    "            new_state.path+=\" -> \"\n",
    "            frontier_states.append(new_state)\n",
    "    if path!=0:\n",
    "        return(path,visited_state_count,total_cost)\n",
    "    return (0,0,0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BFS TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44m\u001b[37mBFS TEST\n",
      "\u001b[0m\n",
      "BFS Result on \u001b[41minput.txt:\n",
      "\u001b[0m\n",
      "\u001b[32mpath: \u001b[37m 1 -> 3 -> 4 -> 5 -> 7 -> 10 -> 11 -> 9 -> 8\n",
      "\u001b[32mnumber of visited states:\u001b[37m 51\n",
      "\u001b[32mminimum cost:\u001b[37m 8\n",
      "\u001b[36maverage time:\u001b[37m 0.009009361267089844\n",
      "\n",
      "BFS Result on \u001b[41minput2.txt:\n",
      "\u001b[0m\n",
      "\u001b[32mpath: \u001b[37m 28 -> 19 -> 13 -> 3 -> 11 -> 24 -> 9 -> 23 -> 28 -> 23 -> 5 -> 7 -> 29\n",
      "\u001b[32mnumber of visited states:\u001b[37m 3631\n",
      "\u001b[32mminimum cost:\u001b[37m 12\n",
      "\u001b[36maverage time:\u001b[37m 5.56989057858785\n",
      "\n",
      "BFS Result on \u001b[41minput3.txt:\n",
      "\u001b[0m\n",
      "\u001b[32mpath: \u001b[37m 40 -> 42 -> 38 -> 24 -> 31 -> 45 -> 30 -> 48 -> 41 -> 18 -> 1 -> 19 -> 43 -> 49 -> 47 -> 49 -> 9 -> 34 -> 25 -> 50 -> 12 -> 16\n",
      "\u001b[32mnumber of visited states:\u001b[37m 3754\n",
      "\u001b[32mminimum cost:\u001b[37m 21\n",
      "\u001b[36maverage time:\u001b[37m 2.983078718185425\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "file_addresses = ['input.txt','input2.txt','input3.txt']\n",
    "print(Back.BLUE+Fore.WHITE+'BFS TEST')\n",
    "print(Style.RESET_ALL)\n",
    "for file_address in file_addresses:\n",
    "    time_sum=0\n",
    "    for i in range(3):\n",
    "        start_time=time.time()\n",
    "        path, visited_states_number, cost=BFS(file_address)\n",
    "        end_time=time.time()\n",
    "        time_sum += end_time-start_time\n",
    "    time_mean = time_sum/3\n",
    "    print(\"BFS Result on \"+Back.RED+ file_address+\":\")\n",
    "    print(Style.RESET_ALL)\n",
    "    print(Fore.GREEN+ \"path: \" +Fore.WHITE,path)\n",
    "    print(Fore.GREEN+ \"number of visited states:\" +Fore.WHITE,str(visited_states_number))\n",
    "    print(Fore.GREEN+ \"minimum cost:\" +Fore.WHITE ,str(cost))\n",
    "    print(Fore.CYAN+\"average time:\"+Fore.WHITE,str(time_mean))\n",
    "    print()\n",
    "print(Style.RESET_ALL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another test added by myself for testing difficult vertices because of a previously problem on a loop in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test for difficult vertices problem:\n",
      "1 -> 2 -> 3 -> 2 -> 1 -> 10 29 6\n",
      "0.0035517215728759766\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "path, visited_states_number,cost=BFS(\"input4.txt\")\n",
    "end_time=time.time()\n",
    "print(\"test for difficult vertices problem:\")\n",
    "print(path,visited_states_number,cost)\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDS\n",
    "In IDS function, starting with depth 1, we increment the max_depth for algorithm to find the result recursively using dfs and if a state satisfies the condition of the final state, it returns the result and if not and max_depth is reached, it returns \"0\" as a path(0,visited_state_count,0) and we continue to search for the result in a deeper depth.\n",
    "\n",
    "##### Pros:\n",
    "- It return the optimal solution\n",
    "- It requires lesser memory compare to BFS and A*\n",
    "##### Cons:\n",
    "- It runs slow due to possiblity of visiting some states more than once\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth-Limited search\n",
    "def DLS(initial_state,visited_states,depth,max_depth):\n",
    "    \n",
    "    visited_states=copy.deepcopy(visited_states)\n",
    "    frontier_states = deque()\n",
    "    frontier_states.append(initial_state)\n",
    "    visited_state_count = 1\n",
    "    path,total_cost=0,float('inf')\n",
    "    while (frontier_states):\n",
    "        present_state = frontier_states.pop()\n",
    "        encoded_state = state_encoder(present_state)\n",
    "        if encoded_state in visited_states:\n",
    "            if visited_states[encoded_state]<=depth:\n",
    "                continue\n",
    "        else:\n",
    "            visited_states[encoded_state]=depth\n",
    "            visited_state_count += 1      \n",
    "        \n",
    "        if is_final_state(present_state):   \n",
    "            return (present_state.path, visited_state_count, present_state.total_cost)\n",
    "\n",
    "        if depth+1 > max_depth:\n",
    "            return (0,visited_state_count,0)\n",
    "\n",
    "        neighbors_dict=[item for item in present_state.edges if present_state.seyed_location in item]\n",
    "        for neighbor in neighbors_dict:\n",
    "            if neighbor[0]==present_state.seyed_location:\n",
    "                this_frontier=neighbor[1]\n",
    "            else:\n",
    "                this_frontier=neighbor[0]\n",
    "            \n",
    "            new_state = expand(present_state=present_state,this_frontier=this_frontier)\n",
    "            new_state.path += str(new_state.seyed_location)\n",
    "            new_state.path += \" -> \"\n",
    "            \n",
    "            path1 , total_visited_state_count , total_cost1 = DLS(initial_state= new_state,visited_states=visited_states,depth=depth+1,max_depth=max_depth)\n",
    "            visited_state_count+=total_visited_state_count         \n",
    "            \n",
    "            # check if there is a better way in this depth\n",
    "            if path1 != 0:\n",
    "                if total_cost > total_cost1:\n",
    "                    path,total_cost = path1,total_cost1\n",
    "    \n",
    "    if path!=0:\n",
    "        return(path,visited_state_count,total_cost)\n",
    "    return (0,visited_state_count,0)\n",
    "    \n",
    "\n",
    "\n",
    "def IDS(input_file_address):\n",
    "    \n",
    "    initial_state=open_file(input_file_address)\n",
    "    depth=0\n",
    "    total_visited_state_number=0\n",
    "    \n",
    "    while True:\n",
    "        visited_states={}\n",
    "        path, visited_states_number, cost=DLS(initial_state=initial_state,visited_states=visited_states,depth=0,max_depth=depth)\n",
    "        total_visited_state_number+=visited_states_number\n",
    "        if path!=0:\n",
    "            return (path, total_visited_state_number, cost,depth) \n",
    "        depth += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDS TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44m\u001b[37mIDS TEST\n",
      "\u001b[0m\n",
      "IDS Result on \u001b[41minput-easy.txt:\u001b[49m\n",
      "\u001b[32mpath: \u001b[37m 1 -> 3 -> 4 -> 5 -> 7 -> 10 -> 11 -> 9 -> 8 -> \n",
      "\u001b[32mnumber of visited states:\u001b[37m 1860\n",
      "\u001b[32mminimum cost:\u001b[37m 8\n",
      "\u001b[32mdepth reached:\u001b[37m 8\n",
      "\u001b[36maverage time:\u001b[37m 0.0762181282043457\n",
      "\n",
      "\u001b[0m\n",
      "IDS Result on \u001b[41minput2-easy.txt:\u001b[49m\n",
      "\u001b[32mpath: \u001b[37m 9 -> 10 -> 9 -> 4 -> 12 -> 3 -> 7 -> 5 -> 8 -> \n",
      "\u001b[32mnumber of visited states:\u001b[37m 3639\n",
      "\u001b[32mminimum cost:\u001b[37m 8\n",
      "\u001b[32mdepth reached:\u001b[37m 8\n",
      "\u001b[36maverage time:\u001b[37m 0.15729951858520508\n",
      "\n",
      "\u001b[0m\n",
      "IDS Result on \u001b[41minput3-easy.txt:\u001b[49m\n",
      "\u001b[32mpath: \u001b[37m 13 -> 11 -> 10 -> 3 -> 2 -> 6 -> 12 -> 5 -> 9 -> 4 -> 1 -> 13 -> 11 -> 10 -> \n",
      "\u001b[32mnumber of visited states:\u001b[37m 75705\n",
      "\u001b[32mminimum cost:\u001b[37m 13\n",
      "\u001b[32mdepth reached:\u001b[37m 13\n",
      "\u001b[36maverage time:\u001b[37m 3.320495367050171\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "file_addresses = ['input-easy.txt','input2-easy.txt','input3-easy.txt']\n",
    "print(Back.BLUE+Fore.WHITE+'IDS TEST')\n",
    "print(Style.RESET_ALL)\n",
    "for file_address in file_addresses:\n",
    "    time_sum=0\n",
    "    for i in range(3):\n",
    "        start_time=time.time()\n",
    "        path, visited_states_number, cost,depth=IDS(file_address)\n",
    "        end_time=time.time()\n",
    "        time_sum += end_time-start_time\n",
    "    time_mean = time_sum/3\n",
    "    print(\"IDS Result on \"+Back.RED+ file_address+\":\"+Back.RESET)\n",
    "    print(Fore.GREEN+ \"path: \" +Fore.WHITE,path)\n",
    "    print(Fore.GREEN+ \"number of visited states:\" +Fore.WHITE,str(visited_states_number))\n",
    "    print(Fore.GREEN+ \"minimum cost:\" +Fore.WHITE ,str(cost))\n",
    "    print(Fore.GREEN+ \"depth reached:\" +Fore.WHITE,str(depth))\n",
    "    print(Fore.CYAN+\"average time:\"+Fore.WHITE,str(time_mean))\n",
    "    print()\n",
    "    print(Style.RESET_ALL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heap is specialized for performing push and pop based on the key given to it.\\\n",
    "Key = (total cost of the path) + (alpha * defined heuristic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateHeap:\n",
    "    def __init__(self, key=lambda x:x):\n",
    "        self.key = key\n",
    "        self.index = 0\n",
    "        self._data = []\n",
    "\n",
    "    def push(self, item):\n",
    "        heapq.heappush(self._data, (self.key(item), self.index, item))\n",
    "        self.index += 1\n",
    "\n",
    "    def pop(self):\n",
    "        return heapq.heappop(self._data)[2]\n",
    "\n",
    "    def __bool__(self):\n",
    "        return bool(self._data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heuristic for A*\n",
    "we choose our heuristic number of the nodes that has morids or recipes and they have not been visited yet.\\\n",
    "for a heuristic function to be consistent, we must prove for every successor $P$ of $N$ :\n",
    "$$h(N)\\leq c(N,P)+h(P)$$\n",
    "In every new state a Morid may be satisfy or a new recipe may be collected. Therefore for every successor $P$ of $N$ we have $h(N) \\leq h(P)$. Between every two nodes in our graph we have $c(U,V)\\geq 0$.\\\n",
    "So in this heuristic, $h(N)\\leq c(N,P)+h(P)$ and therefor heuristic is consistent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(state : Graph):\n",
    "    not_empty_nodes= state.get_not_empty_nodes_count()\n",
    "    visited_morid_recipe_count = state.get_recipe_or_morids_visited_count()\n",
    "    to_be_visited_nodes_count = not_empty_nodes-visited_morid_recipe_count\n",
    "    return to_be_visited_nodes_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A*\n",
    "It is a mix of BFS and heuristic function.\n",
    "##### Pros:\n",
    "- It returns an optimal solution\n",
    "- It has a very good time complexity due to visiting less states in comparison with IDS and BFS\n",
    "##### Cons:\n",
    "- Sometimes it's hard to find a good heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_star(input_file_address,alpha=1):\n",
    "\n",
    "    frontier_states=StateHeap(lambda state: state.total_cost + alpha*heuristic(state))\n",
    "    visited_states=set()\n",
    "    initial_state=open_file(input_file_address)\n",
    "    frontier_states.push(initial_state)\n",
    "    \n",
    "    visited_state_count=1\n",
    "    path,total_cost=0,float('inf')\n",
    "    while(frontier_states):\n",
    "        present_state=frontier_states.pop()\n",
    "        encoded_state=state_encoder(present_state)\n",
    "        if encoded_state in visited_states:\n",
    "            continue\n",
    "        else:\n",
    "            visited_states.add(encoded_state)\n",
    "            visited_state_count+=1\n",
    "        \n",
    "        \n",
    "        neighbors_dict=[item for item in present_state.edges if present_state.seyed_location in item]\n",
    "        for neighbor in neighbors_dict:\n",
    "            if neighbor[0]==present_state.seyed_location:\n",
    "                this_frontier=neighbor[1]\n",
    "            else:\n",
    "                this_frontier=neighbor[0]\n",
    "\n",
    "            new_state=expand(present_state=present_state,this_frontier=this_frontier)\n",
    "            new_state.path+=str(new_state.seyed_location)\n",
    "\n",
    "            if is_final_state(new_state):\n",
    "                if total_cost > new_state.total_cost:\n",
    "                    path,total_cost = new_state.path,new_state.total_cost\n",
    "\n",
    "            new_state.path+=\" -> \"\n",
    "            frontier_states.push(new_state)\n",
    "           \n",
    "            if path!=0:\n",
    "                return(path,visited_state_count,total_cost)\n",
    "    return (0,0,0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A* TEST ($\\alpha=1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44m\u001b[37mA* TEST(alpha=1)\n",
      "\u001b[0m\n",
      "A* Result on \u001b[41minput.txt:\n",
      "\u001b[0m\n",
      "\u001b[32mpath: \u001b[37m 1 -> 3 -> 4 -> 5 -> 7 -> 10 -> 11 -> 9 -> 8\n",
      "\u001b[32mnumber of visited states:\u001b[37m 29\n",
      "\u001b[32mminimum cost:\u001b[37m 8\n",
      "\u001b[36maverage time:\u001b[37m 0.005620241165161133\n",
      "\n",
      "A* Result on \u001b[41minput2.txt:\n",
      "\u001b[0m\n",
      "\u001b[32mpath: \u001b[37m 28 -> 19 -> 13 -> 3 -> 11 -> 24 -> 9 -> 23 -> 5 -> 7 -> 29 -> 22 -> 28\n",
      "\u001b[32mnumber of visited states:\u001b[37m 1046\n",
      "\u001b[32mminimum cost:\u001b[37m 12\n",
      "\u001b[36maverage time:\u001b[37m 1.7522508303324382\n",
      "\n",
      "A* Result on \u001b[41minput3.txt:\n",
      "\u001b[0m\n",
      "\u001b[32mpath: \u001b[37m 40 -> 42 -> 38 -> 24 -> 31 -> 45 -> 30 -> 48 -> 41 -> 18 -> 1 -> 19 -> 43 -> 49 -> 47 -> 49 -> 9 -> 34 -> 25 -> 50 -> 12 -> 16\n",
      "\u001b[32mnumber of visited states:\u001b[37m 2827\n",
      "\u001b[32mminimum cost:\u001b[37m 21\n",
      "\u001b[36maverage time:\u001b[37m 2.151686429977417\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# A* test on alpha=1\n",
    "file_addresses = ['input.txt','input2.txt','input3.txt']\n",
    "print(Back.BLUE+Fore.WHITE+'A* TEST(alpha=1)')\n",
    "print(Style.RESET_ALL)\n",
    "for file_address in file_addresses:\n",
    "    time_sum=0\n",
    "    for i in range(3):\n",
    "        start_time=time.time()\n",
    "        path, visited_states_number, cost=A_star(file_address)\n",
    "        end_time=time.time()\n",
    "        time_sum += end_time-start_time\n",
    "        #print(path, visited_states_number, cost,depth)\n",
    "    time_mean = time_sum/3\n",
    "    print(\"A* Result on \"+Back.RED+ file_address+\":\")\n",
    "    print(Style.RESET_ALL)\n",
    "    print(Fore.GREEN+ \"path: \" +Fore.WHITE,path)\n",
    "    print(Fore.GREEN+ \"number of visited states:\" +Fore.WHITE,str(visited_states_number))\n",
    "    print(Fore.GREEN+ \"minimum cost:\" +Fore.WHITE ,str(cost))\n",
    "    print(Fore.CYAN+\"average time:\"+Fore.WHITE,str(time_mean))\n",
    "    print()\n",
    "print(Style.RESET_ALL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A* Weighted\n",
    "##### Pros:\n",
    "- visits lesser states than normal A* and better time complexity\n",
    "##### Cons:\n",
    "- if $\\alpha$ is not choosen carefully, it's answer may not be optimal.(like $\\alpha=5$ in this example for test3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A* TEST ($\\alpha=1.4$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44m\u001b[37mA* TEST(alpha=1.4)\n",
      "\u001b[0m\n",
      "A* Result on \u001b[41minput.txt:\n",
      "\u001b[0m\n",
      "\u001b[32mpath: \u001b[37m 1 -> 3 -> 4 -> 5 -> 7 -> 10 -> 11 -> 9 -> 8\n",
      "\u001b[32mnumber of visited states:\u001b[37m 24\n",
      "\u001b[32mminimum cost:\u001b[37m 8\n",
      "\u001b[36maverage time:\u001b[37m 0.0042870839436848955\n",
      "\n",
      "A* Result on \u001b[41minput2.txt:\n",
      "\u001b[0m\n",
      "\u001b[32mpath: \u001b[37m 28 -> 19 -> 13 -> 3 -> 11 -> 24 -> 9 -> 23 -> 5 -> 7 -> 29 -> 22 -> 28\n",
      "\u001b[32mnumber of visited states:\u001b[37m 45\n",
      "\u001b[32mminimum cost:\u001b[37m 12\n",
      "\u001b[36maverage time:\u001b[37m 0.10704700152079265\n",
      "\n",
      "A* Result on \u001b[41minput3.txt:\n",
      "\u001b[0m\n",
      "\u001b[32mpath: \u001b[37m 40 -> 42 -> 38 -> 24 -> 31 -> 45 -> 30 -> 48 -> 41 -> 18 -> 1 -> 19 -> 43 -> 49 -> 47 -> 49 -> 9 -> 34 -> 25 -> 50 -> 12 -> 16\n",
      "\u001b[32mnumber of visited states:\u001b[37m 2225\n",
      "\u001b[32mminimum cost:\u001b[37m 21\n",
      "\u001b[36maverage time:\u001b[37m 1.7981499830881755\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# A* test on alpha=1.4\n",
    "file_addresses = ['input.txt','input2.txt','input3.txt']\n",
    "file_addresses = ['input.txt','input2.txt','input3.txt']\n",
    "print(Back.BLUE+Fore.WHITE+'A* TEST(alpha=1.4)')\n",
    "print(Style.RESET_ALL)\n",
    "for file_address in file_addresses:\n",
    "    time_sum=0\n",
    "    for i in range(3):\n",
    "        start_time=time.time()\n",
    "        path, visited_states_number, cost=A_star(file_address,1.4)\n",
    "        end_time=time.time()\n",
    "        time_sum += end_time-start_time\n",
    "        #print(path, visited_states_number, cost,depth)\n",
    "    time_mean = time_sum/3\n",
    "    print(\"A* Result on \"+Back.RED+ file_address+\":\")\n",
    "    print(Style.RESET_ALL)\n",
    "    print(Fore.GREEN+ \"path: \" +Fore.WHITE,path)\n",
    "    print(Fore.GREEN+ \"number of visited states:\" +Fore.WHITE,str(visited_states_number))\n",
    "    print(Fore.GREEN+ \"minimum cost:\" +Fore.WHITE ,str(cost))\n",
    "    print(Fore.CYAN+\"average time:\"+Fore.WHITE,str(time_mean))\n",
    "    print()\n",
    "print(Style.RESET_ALL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A* TEST ($\\alpha=5$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44m\u001b[37mA* TEST(alpha=5)\n",
      "\u001b[0m\n",
      "A* Result on \u001b[41minput.txt:\n",
      "\u001b[0m\n",
      "\u001b[32mpath: \u001b[37m 1 -> 3 -> 4 -> 5 -> 7 -> 10 -> 11 -> 9 -> 8\n",
      "\u001b[32mnumber of visited states:\u001b[37m 15\n",
      "\u001b[32mminimum cost:\u001b[37m 8\n",
      "\u001b[36maverage time:\u001b[37m 0.0028246243794759116\n",
      "\n",
      "A* Result on \u001b[41minput2.txt:\n",
      "\u001b[0m\n",
      "\u001b[32mpath: \u001b[37m 28 -> 19 -> 3 -> 11 -> 24 -> 9 -> 23 -> 5 -> 7 -> 29 -> 20 -> 13 -> 19 -> 28\n",
      "\u001b[32mnumber of visited states:\u001b[37m 16\n",
      "\u001b[32mminimum cost:\u001b[37m 13\n",
      "\u001b[36maverage time:\u001b[37m 0.02593088150024414\n",
      "\n",
      "A* Result on \u001b[41minput3.txt:\n",
      "\u001b[0m\n",
      "\u001b[32mpath: \u001b[37m 40 -> 42 -> 38 -> 24 -> 31 -> 15 -> 12 -> 16 -> 12 -> 49 -> 9 -> 49 -> 47 -> 49 -> 9 -> 34 -> 25 -> 50 -> 10 -> 41 -> 48 -> 41 -> 18 -> 1 -> 19\n",
      "\u001b[32mnumber of visited states:\u001b[37m 76\n",
      "\u001b[32mminimum cost:\u001b[37m 25\n",
      "\u001b[36maverage time:\u001b[37m 0.08561595280965169\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# A* test on alpha=5\n",
    "file_addresses = ['input.txt','input2.txt','input3.txt']\n",
    "print(Back.BLUE+Fore.WHITE+'A* TEST(alpha=5)')\n",
    "print(Style.RESET_ALL)\n",
    "for file_address in file_addresses:\n",
    "    time_sum=0\n",
    "    for i in range(3):\n",
    "        start_time=time.time()\n",
    "        path, visited_states_number, cost=A_star(file_address,5)\n",
    "        end_time=time.time()\n",
    "        time_sum += end_time-start_time\n",
    "        #print(path, visited_states_number, cost,depth)\n",
    "    time_mean = time_sum/3\n",
    "    print(\"A* Result on \"+Back.RED+ file_address+\":\")\n",
    "    print(Style.RESET_ALL)\n",
    "    print(Fore.GREEN+ \"path: \" +Fore.WHITE,path)\n",
    "    print(Fore.GREEN+ \"number of visited states:\" +Fore.WHITE,str(visited_states_number))\n",
    "    print(Fore.GREEN+ \"minimum cost:\" +Fore.WHITE ,str(cost))\n",
    "    print(Fore.CYAN+\"average time:\"+Fore.WHITE,str(time_mean))\n",
    "    print()\n",
    "print(Style.RESET_ALL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `OVERALL RESULT`\n",
    "\n",
    "##### **input.txt**\n",
    "\n",
    "| |Minimum Cost|States Count|Average Time|Depth Reached|\n",
    "|:---|:----:|:----:|:----:|:----:|\n",
    "|BFS|8|51|0.0090|-|\n",
    "|IDS|8|1860|0.0762|8|\n",
    "|A*|8|29|0.0056|-|\n",
    "|Weighted A* 1.4|8|24|0.0042|-|\n",
    "|Weighted A* 5|8|15|0.0028|-|\n",
    "\n",
    "##### **input2.txt** (input2-easy.txt for IDS)\n",
    "\n",
    "| |Minimum Cost|States Count|Average Time|Depth Reached|\n",
    "|:---|:----:|:----:|:----:|:----:|\n",
    "|BFS|12|3631|5.5698|-|\n",
    "|IDS|8|3639|0.1572|8|\n",
    "|A*|12|1046|1.7522|-|\n",
    "|Weighted A* 1.4|12|45|0.1070|-|\n",
    "|Weighted A* 5|13|16|0.0259|-|\n",
    "\n",
    "##### **input3.txt** (input3-easy.txt for IDS)\n",
    "\n",
    "| |Minimum Cost|States Count|Average Time|Depth Reached|\n",
    "|:---|:----:|:----:|:----:|:----:|\n",
    "|BFS|21|3754|2.9830|-|\n",
    "|IDS|13|75705|3.3204|13|\n",
    "|A*|21|2827|2.1516|-|\n",
    "|Weighted A* 1.4|21|2225|1.7981|-|\n",
    "|Weighted A* 5|25|76|0.0856|-|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e64eb598fbc2e16264e8c631fe01bfcba68a02dcc3894a9e95dce8995079460"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
